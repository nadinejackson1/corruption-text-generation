{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-27 11:03:10.884415: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Embedding\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset \n",
    "data = pd.read_csv('/Users/nadinejackson/Downloads/corruption-perceptions-index-cpi.csv')\n",
    "\n",
    "# Convert data into DataFrame\n",
    "data = pd.DataFrame([\n",
    "    ['Benin', 42, 41, 41, 40, 39, 36, 37, 39, 36, 36],\n",
    "    ['Botswana', 55, 60, 61, 61, 61, 60, 63, 63, 64, 65],\n",
    "    ['Cabo Verde', 58, 58, 58, 57, 55, 59, 55, 57, 58, 60],\n",
    "    ['Ethiopia', 39, 38, 37, 34, 35, 34, 33, 33, 33, 33],\n",
    "    ['Kenya', 30, 31, 28, 27, 28, 26, 25, 25, 27, 27],\n",
    "    ['Nigeria', 24, 25, 26, 27, 27, 28, 26, 27, 25, 27],\n",
    "    ['Senegal', 43, 45, 45, 45, 45, 45, 44, 43, 41, 36],\n",
    "    ['South Africa', 44, 44, 44, 43, 43, 45, 44, 44, 42, 43],\n",
    "    ['Sudan', 20, 16, 16, 16, 16, 14, 12, 11, 11, 13],\n",
    "    ['Tanzania', 39, 38, 37, 36, 36, 32, 30, 31, 33, 35],\n",
    "    ['Zambia', 33, 33, 34, 35, 37, 38, 38, 38, 38, 37]\n",
    "], columns=['Country', 2021, 2020, 2019, 2018, 2017, 2016, 2015, 2014, 2013, 2012])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "text_data = ''\n",
    "for _, row in data.iterrows():\n",
    "    country = row['Country']\n",
    "    for year in range(2012, 2022):\n",
    "        text_data += f\"{country} has a corruption score of {row[year]} in {year}. \"\n",
    "\n",
    "tokenizer = Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts([text_data])\n",
    "\n",
    "sequence_data = tokenizer.texts_to_sequences([text_data])[0]\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "seq_length = 100\n",
    "input_sequences = []\n",
    "output_char = []\n",
    "\n",
    "for i in range(0, len(sequence_data) - seq_length):\n",
    "    input_sequences.append(sequence_data[i:i+seq_length])\n",
    "    output_char.append(sequence_data[i+seq_length])\n",
    "\n",
    "X = np.array(input_sequences)\n",
    "y = tf.keras.utils.to_categorical(output_char, num_classes=vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and pad the sequences\n",
    "tokenizer = Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts([text_data])\n",
    "\n",
    "sequence_data = tokenizer.texts_to_sequences([text_data])[0]\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "seq_length = 100\n",
    "input_sequences = []\n",
    "output_char = []\n",
    "\n",
    "for i in range(0, len(sequence_data) - seq_length):\n",
    "    input_sequences.append(sequence_data[i:i+seq_length])\n",
    "    output_char.append(sequence_data[i+seq_length])\n",
    "\n",
    "X = np.array(input_sequences)\n",
    "y = tf.keras.utils.to_categorical(output_char, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-27 11:03:17.481104: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-27 11:03:17.485507: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-27 11:03:17.487630: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 128)          4608      \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100, 256)          394240    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100, 256)          0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 256)               525312    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 36)                9252      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 933,412\n",
      "Trainable params: 933,412\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-27 11:03:17.874811: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-27 11:03:17.878206: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-27 11:03:17.881464: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "# Define the RNN model using LSTM layers\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 128, input_length=seq_length))\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-27 11:03:19.007728: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-27 11:03:19.016705: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-27 11:03:19.033621: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-27 11:03:20.434120: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-27 11:03:20.438817: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-27 11:03:20.442287: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-27 11:03:25.016909: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-27 11:03:25.021352: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-27 11:03:25.025445: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-27 11:03:26.186691: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-27 11:03:26.192116: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-27 11:03:26.195163: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - ETA: 0s - loss: 3.0043 - accuracy: 0.1877"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-27 11:04:47.763660: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-27 11:04:47.766651: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-27 11:04:47.769225: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-27 11:04:48.274229: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-27 11:04:48.277402: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-27 11:04:48.280612: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 2.87730, saving model to corruption_rnn.h5\n",
      "63/63 [==============================] - 97s 1s/step - loss: 3.0043 - accuracy: 0.1877 - val_loss: 2.8773 - val_accuracy: 0.1970\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.3422 - accuracy: 0.2828\n",
      "Epoch 2: val_loss improved from 2.87730 to 1.91022, saving model to corruption_rnn.h5\n",
      "63/63 [==============================] - 107s 2s/step - loss: 2.3422 - accuracy: 0.2828 - val_loss: 1.9102 - val_accuracy: 0.4110\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.5037 - accuracy: 0.5332\n",
      "Epoch 3: val_loss improved from 1.91022 to 1.27663, saving model to corruption_rnn.h5\n",
      "63/63 [==============================] - 109s 2s/step - loss: 1.5037 - accuracy: 0.5332 - val_loss: 1.2766 - val_accuracy: 0.6350\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.9862 - accuracy: 0.7092\n",
      "Epoch 4: val_loss improved from 1.27663 to 1.00528, saving model to corruption_rnn.h5\n",
      "63/63 [==============================] - 110s 2s/step - loss: 0.9862 - accuracy: 0.7092 - val_loss: 1.0053 - val_accuracy: 0.7370\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.8100\n",
      "Epoch 5: val_loss improved from 1.00528 to 0.90417, saving model to corruption_rnn.h5\n",
      "63/63 [==============================] - 109s 2s/step - loss: 0.6848 - accuracy: 0.8100 - val_loss: 0.9042 - val_accuracy: 0.7500\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.5372 - accuracy: 0.8328\n",
      "Epoch 6: val_loss improved from 0.90417 to 0.86652, saving model to corruption_rnn.h5\n",
      "63/63 [==============================] - 133s 2s/step - loss: 0.5372 - accuracy: 0.8328 - val_loss: 0.8665 - val_accuracy: 0.7880\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.4370 - accuracy: 0.8618\n",
      "Epoch 7: val_loss improved from 0.86652 to 0.82567, saving model to corruption_rnn.h5\n",
      "63/63 [==============================] - 156s 2s/step - loss: 0.4370 - accuracy: 0.8618 - val_loss: 0.8257 - val_accuracy: 0.8300\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.3494 - accuracy: 0.8860\n",
      "Epoch 8: val_loss did not improve from 0.82567\n",
      "63/63 [==============================] - 154s 2s/step - loss: 0.3494 - accuracy: 0.8860 - val_loss: 0.9338 - val_accuracy: 0.7980\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.2995 - accuracy: 0.9035\n",
      "Epoch 9: val_loss did not improve from 0.82567\n",
      "63/63 [==============================] - 127s 2s/step - loss: 0.2995 - accuracy: 0.9035 - val_loss: 0.8757 - val_accuracy: 0.8060\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.2685 - accuracy: 0.9107\n",
      "Epoch 10: val_loss did not improve from 0.82567\n",
      "63/63 [==============================] - 110s 2s/step - loss: 0.2685 - accuracy: 0.9107 - val_loss: 0.9799 - val_accuracy: 0.8050\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.2377 - accuracy: 0.9165\n",
      "Epoch 11: val_loss did not improve from 0.82567\n",
      "63/63 [==============================] - 100s 2s/step - loss: 0.2377 - accuracy: 0.9165 - val_loss: 0.9746 - val_accuracy: 0.8090\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.2188 - accuracy: 0.9205\n",
      "Epoch 12: val_loss did not improve from 0.82567\n",
      "63/63 [==============================] - 86s 1s/step - loss: 0.2188 - accuracy: 0.9205 - val_loss: 1.0006 - val_accuracy: 0.8050\n",
      "Epoch 12: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and validation sets\n",
    "split_ratio = 0.8\n",
    "train_size = int(len(X) * split_ratio)\n",
    "X_train, X_val = X[:train_size], X[train_size:]\n",
    "y_train, y_val = y[:train_size], y[train_size:]\n",
    "\n",
    "# Train the model with early stopping based on validation loss\n",
    "checkpoint = ModelCheckpoint(\"corruption_rnn.h5\", monitor='val_loss', save_best_only=True, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=64, callbacks=[checkpoint, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate text using the trained model\n",
    "def generate_text(seed_text, model, tokenizer, seq_length, num_chars):\n",
    "    output_text = seed_text\n",
    "\n",
    "    for _ in range(num_chars):\n",
    "        tokenized_text = tokenizer.texts_to_sequences([seed_text])[-1]\n",
    "        padded_text = pad_sequences([tokenized_text], maxlen=seq_length)\n",
    "\n",
    "        probabilities = model.predict(padded_text)[0]\n",
    "        predicted_index = np.argmax(probabilities)\n",
    "        predicted_char = tokenizer.index_word[predicted_index]\n",
    "\n",
    "        output_text += predicted_char\n",
    "        seed_text += predicted_char\n",
    "\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 188ms/step\n",
      "1/1 [==============================] - 0s 263ms/step\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "1/1 [==============================] - 0s 209ms/step\n",
      "1/1 [==============================] - 0s 254ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "Nigeria has a corruption score of 44 in 2018.\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"Nigeria has a corruption score of \"\n",
    "generated_text = generate_text(seed_text, model, tokenizer, seq_length, 11)\n",
    "print(generated_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
